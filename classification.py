# -*- coding: utf-8 -*-
"""emotion_classification_using_nlp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xELSPUqforRRfDPDoX8Oz3tDJtiY4bNH

# **Membuat Model NLP dengan TensorFlow**
## Emotion Classification using NLP

## Profile

**Achmad Hadi Kurnia**

Link [Dicoding](https://www.dicoding.com/users/achmadhadikurnia)

## Kriteria
- [x] Dataset yang akan dipakai bebas, namun minimal memiliki 1000 sampel.
- [x] Harus menggunakan LSTM dalam arsitektur model.
- [x] Harus menggunakan model sequential.
- [x] Validation set sebesar 20% dari total dataset.
- [x] Harus menggunakan Embedding.
- [x] Harus menggunakan fungsi tokenizer.
- [x] Akurasi dari model minimal 75% pada train set dan validation set.

## Saran untuk Penilaian Lebih Tinggi
- [x] Akurasi dari model di atas 80%.
- [x] Mengimplementasikan callback.
- [x] Membuat plot loss dan akurasi pada saat training dan validation.

### 1. Setup Kebutuhan
"""

# Unduh dataset
!wget https://raw.githubusercontent.com/achmadhadikurnia/emotion-classification-nlp-dicoding-submission/main/datasets/data.csv

# Impor libary
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

"""### 2. Menyiapkan data"""

# Menampilkan mapping data
data = pd.read_csv('/content/data.csv', delimiter=',')
label = pd.get_dummies(data.label)
unique_labels = data['label'].unique()
size_unique_labels = len(unique_labels)
new_data = pd.concat([data, label], axis=1)
new_data = new_data.drop(columns=['label'])
new_data

"""### 3. Tokenisasi dan Sequential"""

sentence = new_data['text'].values
label = new_data[unique_labels].values
sentence_latih, sentence_test, label_latih, label_test = train_test_split(sentence, label, test_size = 0.2)

# Tokenizer
tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(sentence_latih)
tokenizer.fit_on_texts(sentence_test)

sequences_latih = tokenizer.texts_to_sequences(sentence_latih)
sequences_test = tokenizer.texts_to_sequences(sentence_test)

padded_latih = pad_sequences(sequences_latih)
padded_test = pad_sequences(sequences_test)

# Sequential
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim = 5000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(size_unique_labels, activation='softmax'),
])

model.compile(
  loss='categorical_crossentropy',
  optimizer='adam',
  metrics=['accuracy'],
)
model.summary()

"""## 4. Modeling"""

# Callback
class accuracyCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.90 and logs.get('val_accuracy') > 0.90):
      print('\nNilai akurasi telah mencapai 90%')
      self.model.stop_training = True

callbacks = accuracyCallback()

history = model.fit(
  padded_latih,
  label_latih,
  epochs=30,
  validation_data=(padded_test, label_test),
  verbose=2,
  callbacks=[callbacks],
)

"""## 5. Plot"""

# Membuat plot model accuracy
plt.figure(figsize=(8,5))
plt.plot(history.history['accuracy'], label='train_accuracy')
plt.plot(history.history['val_accuracy'], label='validation_accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.ylim(ymin=0, ymax=1)
plt.show()

# Membuat plot model lost
plt.figure(figsize=(8,5))
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='validation_loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.ylim(ymin=0)
plt.show()